# Code Used for Benchmarking

`ann_unann_scatter.py`: Prints numbers for annotated/unannotated junctions in real datasets and Figure 3 A, Supplementary Figure 3 

`shared_concordance.py`: Prints numbers for agreement between junctions called in individuals of the same species and Figure 3 C-D

`count_tables.py`: Outputs tables of the number of annotated and unannotated junctions passing each criteria in each individual.

`figure_1E.R`: Generates the ROC curves in Figure 1E based on the simulated benchmarking datasets. It takes as inputs the benchmarking data that are in `bechmarking_files` folder
